{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "35af6a63",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "87e2cdb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data manipulation\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "\n",
    "# Data visualization\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import plotly.express as px\n",
    "import plotly.graph_objects as go\n",
    "from sklearn.model_selection import learning_curve\n",
    "from sklearn.model_selection import validation_curve\n",
    "\n",
    "# preprocessing and resampling\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from imblearn.over_sampling import SMOTE\n",
    "\n",
    "# metrics\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import recall_score\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "# ML model\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "import sklearn\n",
    "from distfit import distfit\n",
    "\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import FunctionTransformer\n",
    "from imblearn.pipeline import Pipeline\n",
    "\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import FunctionTransformer\n",
    "from imblearn.pipeline import Pipeline\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.pipeline import Pipeline \n",
    "from imblearn.combine import SMOTETomek \n",
    "from sklearn.compose import ColumnTransformer \n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "from imblearn.pipeline import Pipeline as imbpipeline\n",
    "\n",
    "from imblearn.combine import SMOTEENN\n",
    "\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.preprocessing import minmax_scale\n",
    "from sklearn.preprocessing import MaxAbsScaler\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import RobustScaler\n",
    "from sklearn.preprocessing import Normalizer\n",
    "from sklearn.preprocessing import QuantileTransformer\n",
    "from sklearn.preprocessing import PowerTransformer\n",
    "\n",
    "\n",
    "np.warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e38cc79a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Load Dataset\n",
    "df_test = pd.read_csv(\"C:/Users/User/Desktop/Faillite/data/data.csv\")\n",
    "df_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab3c7c0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# drop the space before title of columns\n",
    "df.columns = [c.replace(\" \",\"\", 1) if c.startswith(' ') else c for c in df.columns]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acc55e96",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Drop columns \n",
    "df = df.drop(['Net Income Flag', \"Liability-Assets Flag\"], axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0340a562",
   "metadata": {},
   "outputs": [],
   "source": [
    "#split data\n",
    "#On définit les features et la Target\n",
    "X = df_model.drop(['Bankrupt?'], axis = 1)\n",
    "y = df_model['Bankrupt?']\n",
    "# Splitting the data\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=.3, random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6fd8579",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = X_train.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4cc57baf",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Distribution "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76d362e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Boucle pour itérations \n",
    "# Fit\n",
    "from distfit import distfit\n",
    "norm_dis =[]\n",
    "t_dis =[]\n",
    "log_dis = []\n",
    "autre_dis = []\n",
    "\n",
    "distfit = distfit(bins=25,alpha=0.02,stats='ks')\n",
    "\n",
    "for col in X.columns:\n",
    "    distfit.fit_transform(X[col], verbose=1)\n",
    "    if distfit.model[\"name\"] == \"t\":\n",
    "        t_dis.append([col, distfit.model[\"score\"]])\n",
    "    elif distfit.model[\"name\"] == \"norm\":\n",
    "         norm_dis.append([col, distfit.model[\"score\"]])\n",
    "    elif distfit.model[\"name\"] == \"lognorm\":\n",
    "         log_dis.append([col, distfit.model[\"score\"]])\n",
    "    else:   \n",
    "        #autre_dis.append([col, distfit.model[\"score\"], distfit.model[\"name\"]])\n",
    "        autre_dis.append([col, distfit.model[\"score\"]])\n",
    "\n",
    "t_dis = pd.DataFrame(t_dis, columns=[\"feature\", \"score\"])\n",
    "norm_dis = pd.DataFrame(norm_dis, columns=[\"feature\", \"score\"])\n",
    "log_dis = pd.DataFrame(log_dis, columns=[\"feature\", \"score\"])\n",
    "autre_dis = pd.DataFrame(autre_dis, columns=[\"feature\", \"score\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5dfc9998",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Application modèle de prediction "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5bf753a",
   "metadata": {},
   "outputs": [],
   "source": [
    "my_model_rfc = pickle.load(open(\"rfc_pickle.pkl\",\"rb\")) \n",
    "y_pred = pipeline_rfc.predict(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be2b0c1f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
